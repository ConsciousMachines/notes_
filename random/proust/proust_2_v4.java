// ----------------------------------------------------------------------------
//                    inference rules 1: lambda calculus
// ----------------------------------------------------------------------------

// these are the first 3 inference rules that correspond lambda calculus
// together with the logical rules for implication.

//  Gam, x:T |- t <= W
// --------------------- (-> intro)
//  Gam |- \x.t <= T->W
// to check that a lambda term \x.t has type T->W, we need to augment the
// context Gam with x:T and check that t has type W in this new context.
// for example, to show that \x.x has type A->A, we add x:A to the context,
// and check that the body x has type A in this context. to check variable
// x (from body) we then look in the context to find the x:A (from input).
// so the arrow allows us to fill the context with a variable name that we
// create like a,b,c.. and a type which is the arrow's domain type.

//  Gam |- f => T->W  Gam |- a <= T
// ---------------------------------- (-> elim)
//         Gam |- f a => W
// to synthesize a type for function application (f a) we must synthesize
// an unknown type T. thus we synthesize a type T->W for f, and then check
// that the input a matches that input type.
// to synthesize an arrow type for f would require that we have the proper
// assumptions in our context. so all we are doing is checking our
// assumptions rather than magically invent a type to work, since the
// recursive call to synth-type will look for f in the context.

//
// -------------------- (Var)
//  Gam, x:X |- x => X
// to synthesize a type for a variable we can find it in the context.
// this means we hopefully have the right variable added to the context
// through the "assumptions" generated by arrow (if a:A then b:B)

// ----------------------------------------------------------------------------
//                        inference rules 2: AND
// ----------------------------------------------------------------------------

// we now add inference rules that correspond to logical AND, and add
// structs to lambda calculus which act as boxes around 1 or 2 values.

//  Gam |- t <= T  Gam |- w <= W
// -------------------------------- (and-intro)
//  Gam |- and-intro(t,w) <= T & W
// to check that a struct consisting of values t and w has type T & W,
// we check that individually t has type T and w has type W.

//     Gam |- v => T & W
// -------------------------- (and-elim0)
//  Gam |- and-elim0(v) => T
// to synthesize a type for a "box" and-elim0 (which contains a term inside
// that we put in there, so we'd only put an and-term inside it) we have to
// synthesize the type of the original term (once again, since we wrote this,
// we'd only put an and-term with an and-type inside) and then extract the
// left type out.

//     Gam |- v => T & W
// -------------------------- (and-elim1)
//  Gam |- and-elim1(v) => W
// symmetric to and-elim0.

// ----------------------------------------------------------------------------
//                          inference rules 3: OR
// ----------------------------------------------------------------------------

//         Gam |- t <= T
// ------------------------------ (or-intro0)
//  Gam |- or-intro0(t) <= T | W
// to check that a "box" or-intro0 has type T | W, we throw out its right
// type and check that the element inside has the left type.
// when constructing such a term we take a term of known type T and then
// in effect add a wildcard type to the right, since it will be ignored
// in the type check process.
// so to prove that a term has type A | BOB_SAGET we simply need to have
// a term of type A in the context, and apply or-intro0 to it. when the
// type checker checks this term, BOB_SAGET is ignored and we only confirm
// that the boxed term has type A.

//         Gam |- w <= W
// ------------------------------ (or-intro1)
//  Gam |- or-intro1(w) <= T | W
// symmetric to or-intro0.

//  Gam |- d => T | W  Gam |- f <= T->V  Gam |- g <= W->V
// ------------------------------------------------------- (or-elim)
//                Gam |- v-elim(d,f,g) <= V
// to check that a box has type V, we first synthesize the type of d.
// we want the type of d to be an OR type so we can then create 2 functions
// from the left and right parts of the OR, and outputting type V.
// knowing these desired function types T->V and W->V, we check that f,g
// actually have those types.
// when we create an or-elim object, we have an output type in mind (V) and
// we plan to get rid of both of the possible input types (T | W). this is
// done by supplying two lambdas that will be checked against those Arrow
// types. this is interesting because we never had anything of type T or W
// in the context, but once the lambdas start being checked, their inputs
// are added to the context as types T and W respectively, per subtree.

// ----------------------------------------------------------------------------
//                      inference rules 4: negation
// ----------------------------------------------------------------------------

//      Gam |- t <= Bot
// ------------------------- (bot-elim)
//  Gam |- bot-elim(t) <= T
// if we want to show that the box bot-elim has type BOB_SAGET we just need
// to show that its premise is absurdity.
// say we are buildin gour proof tree and a node has type absurdity. we
// apply bot-elim to it. now when the type checker works its way up, and is
// asked to check whether bot-elim(t) has type BOB_SAGET, it asks: well, does
// t have type Bot? yes. then bot-elim(t) has type BOB_SAGET.

// ----------------------------------------------------------------------------
//                                 notes
// ----------------------------------------------------------------------------

// when we are proving a formula, we apply inference rules in 2 directions:

// 1. we can apply inference rules to things in the context, and
// build a proof tree downwards. we apply intro or elim rules
// by putting variables from context into the rules' premises to get a result.

// 2. we can work upwards by decomposing the root node into a variable
// for the context, and a new sub-goal (A->B). this applies rules backwards
// because we pattern-match the formula into (A->B) to generate the premise
// A for the context, and B for the new sub-goal. Note that only the (-> intro)
// rule does this so far, and it's more like (arrow intro backwards) so
// we can think of it as "undoing arrow introduction".

// no matter if we work upwards or downwards, we are constructing a proof tree.
// the node of this tree is passed to the type checker which then works
// starting at the goal and working back towards the premises.

// we implicitly implemented TURN because all the default cases in
// type-check are passed to type-synth.

// a constructor is something that creates a new entity, in our case the
// bottom line of every introduction rule:
// and-intro, or-intro0, or-intro1, and lambda.
// we construct this lambda-calculus entity, and its type, by applying the
// constructor (which corresponds to applying the logical inference rule)
// to the premises.
// so the object it constructs is a piece of proof tree, ie a lambda-calculus
// term, and its corresponding type.
// interestingly, the eliminator does not remove anything from the proof tree.
// instead it eliminates something from the type, but this is done by further
// applying the elimination inference rule to the premises, which further
// builds the proof tree. only the type is simplified. We have:
// -> elim, and-elim0, and-elim1, or-elim.
// thus constructors and eliminators both grow the proof tree.
// constructors construct new types for the resulting term.
// eliminators simplify the type of the resulting term.
// since the type is also a tree, the type can grow or shrink.

// concretely, in this program i build the proof tree manually because
// i dont wanna write a parser. Both constructors and eliminators are
// implemented in the functions such as Term.lam, Term.app, Term.or_elim.
// all they do is add nodes to the tree.
// CONCRETELY, the constructors and eliminators are whatever java code
// actually creates a new node in the proof tree and puts it in the tree.
// in this case they are the static Term functions that create new Term
// structs and link them with other terms. makes sense...
// and each such function corresponds to an inference rule (if used correctly,
// hence the need for type checking)

// whether the nodes are added as dictated by the inference rules is up to me.
// it is implied that i am following the rules of inference when i build
// the tree. but the type checker is where the rules of inference are
// implemented because it checks that the nodes of the tree are formed
// according to these rules.

// so why a type checker and not a tree-walking interpreter?
// well there is no actual programming here. i could write the proof trees
// on paper, but instead the rules of inference are mapped to programming
// constructs, which happen to be the types of functions.
// it does not make sense to map the concept of "A implies B" to a function
// that takes a value A, amongst other values, and outputs B.
// but if a function takes values of type A and outputs a value of type B,
// the correspondence works. Plus the original correspondence refers to
// simply typed lambda calculus anyways.

// so when i write a tree node of type lambda, and stitch it in the proof
// tree, what im doing is like what a compiler does in building a chain
// of computations, except the types of these functions happen to correspond
// to a proof of a logical formula in a certain logic.

// the inference rules correspond to constructors.
// constructors create a node in the computation tree of lambda terms.
// but we are not worried about computation for now, only the type.
// because the term's type corresponds to some logical formula.

// a proof of -T is that a proof of T is impossible.
// a proof of Bot is impossible.
// T -> Bot
// thus T is impossible.
// (Note: but a proof of T can also be impossible even if T -/-> Bot)
// a proof of -T is a proof of T -> Bot. thus -T := T->Bot

// ok as i am writing this i guess it's a bit like programming except
// instead of return values we are thinking about the return types.

// any one of: law of excluded middle, double negation, pierce's law
// can be added to IPL to make it into CPL.

// kripke semantics:
// if a variable is at a tree's leaf, its value is 1.
// trees with multiple nodes create a notion of truth corresponding to
// formulas we can prove in IPL.
// (since every node is a leaf of a subtree, i guess this holds forall nodes)
// monotonicity holds for formulas: if a formula is true at a node, it is
// true at all descendants. same for not true formulas.
// what does it mean for a formula to be true in a kripke model?
// (when sentences in Gam are true, so is the result)
// (but with kripke semantics - the 4 rules where -> is about descendants)
// Gam |=k T  :=  forall kripke models t with root r, and all arrangements of
// variables at nodes, if r has W forall W in Gam, then r has T.
// (truth here means the variable is at a node, and thus has value 1)

// soundness in IPL means forall Gam and T, Gam |-ipl T => Gam |=k T
// so if we can prove T, then its kripke model holds.

// (btw, since -> implies that if any descendant world has T then it must
// also have W, means that there is a possibility that some descendant,
// and all of its descendants further down, have T)

// soundness is proved by induction on proof tree
// suppose the rule at the root of proof tree is ->I
// suppose T = V->W and conclusion at root of proof tree is Gam |- V->W
// the premise is Gam,V |- W
// by induction hypothesis on this subtree, Gam,V |=k W
// (*) thus for any kripke model t with root r, forall S in {Gam,V}, r has S, and
// r has W.
// we need to show that Gam |=k V->W
// this means forall kripke models t with root r, forall sentences S in Gam,
// r has S, and for all descendants c, if c has V then c has W too.
// to show this, if we have such a t, by monotonicity, all desendants have
// all the sentences of Gam.
// if a descendant also has V then we know it has {Gam,V}
// the induction hypothesis (*) tells us the descendant has W

// ------------------------------------- Quik Proof
// proof root: Gam |- V->W
// premise: Gam,V |- W
// induction on premise: Gam,V |=k W
//     <any t, root r, r has {Gam,V,W}>
// need to show ind step: Gam |- V->W
//     <any t, root r, r has {Gam}, descendant may have {V,W}>
// know all descendants have Gam by monotonicity
// if a descendant also has V, then apply ind hyp and it has W
// c might be r so this holds for the proof root.

// premise: Gam,V |- W     ----induction---> Gam,V |=k W  (*)
//          ----------- (->I)                tree t, root r: r * Gam,V,W
// root:    Gam |- V->W                      any tree with Gam has descendant c
//                                           c has Gam by monotonicity.
//                                           if c has V, (*) says c has W
//                                           c might be r.
//                                     thus: Gam |=k V->W
//                                     which is the proof root.

// so basically the statements in the proof are like constraints on the
// possible kripke models we can describe. there is no induction on the
// kripke trees themselves, they just exist (forall kripke trees t) and
// they follow the constraints given by the proof steps.
// so to make a correspondence, we show that if all kripke models follow
// the constraint of the proof's premise, then they also follow the
// constraint of the proof's root.
// there is no induction on the kripke trees since descendant c may refer
// to the root node, instead this is used to describe the structure.

// contrapositive of soundness: if kripke model doesn't hold, we can't
// prove the sentence.
// Gam |=/=k T  =>  Gam |-/- T
// if Gam is empty, we can show some formulas of CPL are not provable in IPL

// i think kripke models are designed to be a 1-to-1 map between the possible
// proofs we can construct. with the A or -A example, it looks like the
// classical logic presumes one of them exists. but all IPL-provable formulas
// will otherwise include an arrow which will indicate adding a premise
// (variable) to a world, which is possible for descendants. thus we construct
// a proof that manipulates only existing premises, which are "if"s, which
// we definitely observe. hence the whole constructivism thing.
// constructing one kripke tree that doesn't model a formula is the
// counterexample needed to make a formula wrong, since a true formula
// requires "for all kripke trees t" to hold.

// chapter 3

// classical semantics are given in terms of MODELS: a domain of quantification
// (a set of objects to talk about using forall and there-exists) together
// with an interpretation for the function and relation symbols.

// we quantify over things that are typeable
// forall x W(x)
// forall x : T. W(x)

// the difference between Prop and Pred logic is that in Prop logic the
// variables are completely independent. so if we try to say
// A: willard is a logician
// B: all logicians wear funny hats
// C: willard wears a funny hat
// then (A & B) -> C is not a tautology. this is because C varies by itself:
// when A is true (willard IS a logician) and B is true (all logicians DO
// wear funny hats), then C still takes the values {0,1} because it is
// independent, not tied to anything. thus we cannot encode this argument
// in Prop logic, because it does not allow us to make connections.
// in FOL we can have a set, the set of all logicians.
// willard is a logician, so willard \in this set.
// all logicians wear funny hats:
//     Wears_Funny_Hat(x) = True forall x in {logicians}
// thus we can deduce that Willard wears a funny hat, because:
// 1. forall x:LOGICIAN, Wears_Funny_Hat(x) = True
// 2. Willard:LOGICIAN
// 3. Wears_Funny_Hat(Willard) = True
// this is a case of forall-elim, where we instantiate a specific element.
// for introduction it would be:
//     x:LOGICIAN    Wears_Funny_Hat[X->x] = True
// ------------------------------------------------- (forall-intro)
//     forall x:LOGICIAN Wears_Funny_Hat(x) = True
// in Prop logic, the logical formulas are types like (A -> (B -> (A & B)))
// in Pred logic, same thing. (Forall x:T W) is a type.
// this is just a formula from predicate logic. but it has an element x in it.
// so we need to substitute [X->x] in the formula.
// thus the type depends on the value x.
//     (ok im assuming that would hold for forall-elim since there is no subs
//      step in forall-intro, rather we are introducing the quantified
//      variable X)

// so before i noted that in Prop logic we are working with just types.
// lambda took a type and returned a type, there is not even a notion of
// value anywhere.
// now we have x : T, a proof term for T. and W is a type with a free variable
// X of type T in its body. corresponds to a predicate in FOL that takes
// a member from some domain. now we have a lambda that takes x : T and
// returns W(x). now we are returning more than 1 possible thing.
// although, the type depends on the proof term?
// i think in the little typer this was Pi(x) T->W
// so far the proof term x can appear in W.
// also we have inference rules type : Type
// so really the only thing different is that W is a FOL formula W(x)
// instead of a Propositional variable taking values {0,1}.

// a computation is reducing an expression by stepping
// until it cannot be reduced further. (reduce = perform substitution)

// forall-intro: prove a statement for a generic object of a type.
// then we can instantiate the proof with a specific object.

// there-exists-elim: the element exists, so pick it (give it a name)

// there-exists-intro: a P(a) => there-exists x such that P(x)
// so we need to provide an object a : T and a proof of P(a)

// forall-elim: forall x P(x) => a P(a)
// so just pick an object a : T and apply it to the formula.
// we can instantiate proofs with specific objects to get a specific proof
// for that object.

// BHK says a proof of forall X.T is a construction which permits us to
// transform an object a into a proof of T[X->a]
// i would rephrase it differently:
// forall X.T says for any object X, T(X) holds. thus to prove forall X T,
// we need to take a generix object X and show that T(X) is true (prove T(X))

// for arrow in prop, we substituted a proof term into another proof term.
// here we are substituting into a formula (type)
// actually this says nothing about what we are putting in. just the formula
// has a variable and we substitute into that.

// so if we are substituting something into T, what kind of proof is that?
// like a parametrized proof. If we can prove T(x) for any x, then we proved
// forall x T(x).
// so if we can transform generic object a into a proof T[x->a], we have
// a proof of forall x T(x)

// a proof of there-exists T(x) is an object a and a proof of T(a)

//

// ----------------------------------------------------------------------------
//                                pair
// ----------------------------------------------------------------------------

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;

class Pair<X, Y> {
    public final X x;
    public final Y y;

    public Pair(X x, Y y) {
        this.x = x;
        this.y = y;
    }
}

// ----------------------------------------------------------------------------
//                      parser for simple S-expressions
// ----------------------------------------------------------------------------

class Parser {
    // invariant: 'idx' always points to start of next lexeme, so when using
    // consume_char or consume_symbol, they eat up whitespace after.
    int idx = 0;
    String s = "";

    char curr_char() {
        return s.charAt(idx);
    }

    boolean char_is_whitespace(char c) {
        if ((c == ' ') || (c == '\n') || (c == '\t')) return true;
        return false;
    }

    boolean char_is_reserved(char c) {
        if ((c == '(') || (c == ')')) return true;
        return false;
    }

    void __consume_whitespace() {
        if (idx < s.length()) {
            while (char_is_whitespace(curr_char())) idx++;
        }
    }

    String consume_symbol() {
        int start = idx;
        while (true) {
            char c = curr_char();
            if (char_is_reserved(c) || char_is_whitespace(c)) break;
            idx++;
        }
        String ret = s.substring(start, idx);
        __consume_whitespace();
        return ret;
    }

    void consume_char(char c) {
        if (curr_char() == c) idx++;
        else throw new RuntimeException("expected '" + c + "'");
        __consume_whitespace();
    }

    Type parse_type() {
        Type t;
        if (curr_char() == '-') // (- T) := (T -> Bot)
        {
            consume_char('-');
            t = parse_type();
            return Type.arrow(t, Type.bot());
        }
        if (curr_char() == '(') { // s-expr of form (type op type)
            consume_char('(');
            Type t1 = parse_type();
            String type_op = consume_symbol();
            Type t2 = parse_type();
            consume_char(')');
            if (type_op.equals("->")) t = Type.arrow(t1, t2);
            else if (type_op.equals("&")) t = Type.and(t1, t2);
            else if (type_op.equals("|")) t = Type.or(t1, t2);
            else throw new RuntimeException("unknown operand in type-formula:" + type_op);
        }
        else { // parse symbol
            String symbol = consume_symbol();
            if (symbol.equals("Bot")) {
                return Type.bot();
            }
            else {
                t = Type.var(symbol);
            }
        }
        return t;
    }

    Type parse_type(String s) {
        this.idx = 0;
        this.s = s;
        return this.parse_type();
    }

}

// ----------------------------------------------------------------------------
//                      context is a linked list
// ----------------------------------------------------------------------------

class ContextNode {
    String symbol = null;
    Type type = null;
    ContextNode prev = null;

    public ContextNode() {
    }

    public ContextNode(String symbol, Type type) {
        this.symbol = symbol;
        this.type = type;
    }

    Type assoc(String symbol) {
        if (this.symbol.equals(symbol)) return this.type;
        if (this.prev == null) return null;
        return this.prev.assoc(symbol);
    }

    public String toString() {
        String ret = symbol + " : " + type + "\n";
        if (this.prev != null) ret += this.prev.toString();
        return ret;
    }
}

// ----------------------------------------------------------------------------
//                        nodes for building proof trees
// ----------------------------------------------------------------------------

enum TermType {
    Var, Lam, App, Ann, Hole, And_intro, And_elim0, And_elim1, Or_intro0, Or_intro1, Or_elim,
    Bot_elim,
}

class Term {
    final TermType t;
    final Term fst, snd, thr; // for compound types
    final Type ann_type;      // for annotation
    final String symbol;      // for var
    final Integer hole_num;   // for hole, nullable

    private Term(TermType t, Term fst, Term snd, Type ann_type, String symbol, Integer hole_num,
                 Term thr) {
        this.t = t;
        this.fst = fst;
        this.snd = snd;
        this.ann_type = ann_type;
        this.symbol = symbol;
        this.hole_num = hole_num;
        this.thr = thr;
    }

    public String toString() {
        switch (this.t) {
            case Bot_elim:
                return "(bot-elim " + fst + ")";
            case Or_elim:
                return "(or-elim " + fst + " " + snd + " " + thr + ")";
            case Or_intro1:
                return "(or-intro1 " + fst + ")";
            case Or_intro0:
                return "(or-intro0 " + fst + ")";
            case And_elim1:
                return "(and-elim1 " + fst + ")";
            case And_elim0:
                return "(and-elim0 " + fst + ")";
            case And_intro:
                return "(and-intro " + fst + " " + snd + ")";
            case Var:
                return this.symbol;
            case Lam:
                return "(\\" + fst + "." + snd + ")";
            case App:
                return "(" + fst + " " + snd + ")";
            case Ann:
                return "(" + fst + " : " + ann_type + ")";
            case Hole:
                return "?" + hole_num;
            default:
                throw new RuntimeException("unreachable");
        }
    }

    public boolean is_equal(Term e) {
        if (this.t != e.t) return false;
        switch (this.t) {
            case Or_intro1:
            case Or_intro0:
            case And_elim1:
            case And_elim0:
            case Bot_elim:
                return this.fst.is_equal(e.fst);
            case Lam:
            case App:
            case And_intro:
                return this.fst.is_equal(e.fst) && this.snd.is_equal(e.snd);
            case Or_elim:
                return this.fst.is_equal(e.fst) && this.snd.is_equal(e.snd) && this.thr
                        .is_equal(e.thr);
            case Var:
                return this.symbol.equals(e.symbol);
            case Ann:
                return this.fst.is_equal(e.fst) && this.ann_type.is_equal(e.ann_type);
            case Hole:
                return this.hole_num.equals(e.hole_num);
            default:
                throw new RuntimeException("unreachable");
        }
    }

    // static methods to easily create terms (for interactive proof)

    static Term var(String s) {
        return new Term(TermType.Var, null, null, null, s, 0, null);
    }

    static Term lam(String s, Term body) {
        return new Term(TermType.Lam, Term.var(s), body, null, null, 0, null);
    }

    static Term app(Term rator, Term rand) {
        return new Term(TermType.App, rator, rand, null, null, 0, null);
    }

    static Term ann(Term expr, Type ann_type) {
        return new Term(TermType.Ann, expr, null, ann_type, null, 0, null);
    }

    static Term hole(int hole_num) {
        return new Term(TermType.Hole, null, null, null, null, hole_num, null);
    }

    static Term hole() {
        return new Term(TermType.Hole, null, null, null, null, null, null);
    }

    static Term and_intro(Term t1, Term t2) {
        return new Term(TermType.And_intro, t1, t2, null, null, null, null);
    }

    static Term and_elim0(Term t) {
        return new Term(TermType.And_elim0, t, null, null, null, null, null);
    }

    static Term and_elim1(Term t) {
        return new Term(TermType.And_elim1, t, null, null, null, null, null);
    }

    static Term or_intro0(Term t) {
        return new Term(TermType.Or_intro0, t, null, null, null, null, null);
    }

    static Term or_intro1(Term t) {
        return new Term(TermType.Or_intro1, t, null, null, null, null, null);
    }

    static Term or_elim(Term t1, Term t2, Term t3) {
        return new Term(TermType.Or_elim, t1, t2, null, null, null, t3);
    }

    static Term bot_elim(Term t) {
        return new Term(TermType.Bot_elim, t, null, null, null, null, null);
    }
}

enum TypeKind {Var, Arrow, And, Or, Bot}

class Type {
    final TypeKind k;
    final Type fst, snd; // for compound type
    final String symbol; // for type variable

    private Type(TypeKind k, Type fst, Type snd, String symbol) {
        this.k = k;
        this.fst = fst;
        this.snd = snd;
        this.symbol = symbol;
    }

    public String toString() {
        switch (k) {
            case Bot:
                return "Bot";
            case Arrow:
                return "(" + fst + " -> " + snd + ")";
            case And:
                return "(" + fst + " & " + snd + ")";
            case Or:
                return "(" + fst + " | " + snd + ")";
            case Var:
                return symbol;
            default:
                throw new RuntimeException("unreachable");
        }
    }

    public boolean is_equal(Type t2) {
        if (this.k != t2.k) return false;
        switch (this.k) {
            case Arrow:
            case Or:
            case And:
                return fst.is_equal(t2.fst) && snd.is_equal(t2.snd);
            case Bot:
                return true; // already know their Kinds are Bot
            case Var:
                return this.symbol.equals(t2.symbol);
            default:
                throw new RuntimeException("unreachable");
        }
    }

    static Type bot() {
        return new Type(TypeKind.Bot, null, null, null);
    }

    static Type var(String s) {
        return new Type(TypeKind.Var, null, null, s);
    }

    static Type and(Type t1, Type t2) {
        return new Type(TypeKind.And, t1, t2, null);
    }

    static Type or(Type t1, Type t2) {
        return new Type(TypeKind.Or, t1, t2, null);
    }

    static Type arrow(Type t1, Type t2) {
        return new Type(TypeKind.Arrow, t1, t2, null);
    }
}

// ----------------------------------------------------------------------------
//                             kripke model
// ----------------------------------------------------------------------------

class KripkeNode {
    List<Type> variables = new ArrayList<>(); // variables, formulas, as types
    List<KripkeNode> descendants = new ArrayList<>();

    boolean variables_contain(Type t) {
        for (Type v : variables) if (v.is_equal(t)) return true;
        return false; // no match found
    }

    boolean is_valid() { // the case c = r is proved because r contains its own variables.
        boolean ret = true;
        for (KripkeNode c : descendants) { // for each descendant
            for (Type v : variables) { // for each of my vars
                ret &= c.variables_contain(v); // assert descendant has var
            }
        }
        for (KripkeNode c : descendants) { // also check each descendant is valid
            ret &= c.is_valid();
        }
        return ret;
    }

    boolean is_forced(Type t) {
        switch (t.k) {
            case Bot:
                throw new RuntimeException("cannot force Bot ever");
            case And:
                return this.is_forced(t.fst) && this.is_forced(t.snd);
            case Or:
                return this.is_forced(t.fst) || this.is_forced(t.snd);
            case Var:
                return this.variables_contain(t);
            case Arrow: // if t is valid, all descendants already contain Gam.
                boolean ret = true;
                if (variables_contain(t.fst)) { // check self as well
                    ret &= variables_contain(t.snd);
                }
                for (KripkeNode c : descendants) { // to satisfy t has T->W,
                    if (c.variables_contain(t.fst)) // if c has T, then
                    {
                        ret &= c.variables_contain(t.snd); // c should have W
                    }
                }
                for (KripkeNode c : descendants) { // recursively check other levels
                    ret &= c.is_forced(t);
                }
                return ret;
            default:
                throw new RuntimeException("unreachable");
        }
    }
}

// ----------------------------------------------------------------------------
//                           the main proof assistant
// ----------------------------------------------------------------------------

class proust_2 {

    void type_check(ContextNode ctx, Term expr, Type type) {
        switch (expr.t) {
            case Bot_elim:
                type_check(ctx, expr.fst, Type.bot());
                return;
            case Or_elim:
                Type t_or = type_synth(ctx, expr.fst);
                if (t_or.k != TypeKind.Or)
                    throw new RuntimeException("Or-elim failed to synth OR type");
                type_check(ctx, expr.snd, Type.arrow(t_or.fst, type));
                type_check(ctx, expr.thr, Type.arrow(t_or.snd, type));
                return;
            case Or_intro1:
                if (type.k != TypeKind.Or)
                    throw new RuntimeException("Or-intro1 didn't get OR type");
                type_check(ctx, expr.fst, type.snd);
                return;
            case Or_intro0:
                if (type.k != TypeKind.Or)
                    throw new RuntimeException("Or-intro0 didn't get OR type");
                type_check(ctx, expr.fst, type.fst);
                return;
            case And_intro:
                type_check(ctx, expr.fst, type.fst);
                type_check(ctx, expr.snd, type.snd);
                return;
            case Lam: // backwards of arrow introduction rule
                if (type.k != TypeKind.Arrow)
                    throw new RuntimeException("Lambda not matched with arrow type");
                ContextNode ctx2 = new ContextNode(expr.fst.symbol, type.fst);
                ctx2.prev = ctx; // augment context with input
                type_check(ctx2, expr.snd, type.snd); // check that body has output type
                return;
            case Hole:
                if (refining) { // enter hole in goal table
                    goal_table.put(expr.hole_num, new Pair(type, ctx));
                }
                return;
            default: // send to type-synth, in effect implementing TURN
                Type t_ctx = type_synth(ctx, expr);
                if (!type.is_equal(t_ctx))
                    throw new RuntimeException("failed type synth:" + type + " vs " + t_ctx);
                return;
        }
    }

    Type type_synth(ContextNode ctx, Term expr) {
        Type t;
        switch (expr.t) // Var, Lam, App, Ann, Hole
        {
            case And_elim1:
                t = type_synth(ctx, expr.fst);
                if (t.k == TypeKind.And) return t.snd;
                else throw new RuntimeException("And-elim1 did not synthesize & type");
            case And_elim0:
                t = type_synth(ctx, expr.fst);
                if (t.k == TypeKind.And) return t.fst;
                else throw new RuntimeException("And-elim0 did not synthesize & type");
            case Ann:
                type_check(ctx, expr.fst, expr.ann_type);
                return expr.ann_type;
            case App:
                t = type_synth(ctx, expr.fst); // synthesize function's type
                if (t.k == TypeKind.Arrow) {
                    type_check(ctx, expr.snd, t.fst); // type check the input
                    return t.snd;
                }
                else {
                    throw new RuntimeException("function type did not synthesize to Arrow");
                }
            case Var:
                t = ctx.assoc(expr.symbol); // type from context
                if (t == null) throw new RuntimeException("term not in context: " + expr.symbol);
                return t;
            default:
                throw new RuntimeException("failed to synthesize type");
        }
    }

    boolean refining = false;
    int hole_ctr;
    Parser parser;
    Term current_expr;
    HashMap<Integer, Pair<Type, ContextNode>> goal_table;

    int use_hole_ctr() {
        return hole_ctr++;
    }

    void set_task(String s) {
        parser = new Parser();
        Type t = parser.parse_type(s);
        goal_table = new HashMap<>();
        hole_ctr = 1;
        current_expr = Term.ann(Term.hole(0), t);
        goal_table.put(0, new Pair(t, null));
        System.out.println("\nTask is now\n" + current_expr);
    }

    void print_goal() {
        for (int i : goal_table.keySet()) {
            System.out.println("Goal " + i + " has type: " + goal_table.get(i).x);
            System.out.println("in context\n" + goal_table.get(i).y);
        }
    }

    Term number_new_holes(Term e) {
        switch (e.t) {
            case Bot_elim:
                return Term.bot_elim(number_new_holes(e.fst));
            case Or_elim:
                return Term.or_elim(number_new_holes(e.fst), number_new_holes(e.snd),
                                    number_new_holes(e.thr));
            case Or_intro1:
                return Term.or_intro1(number_new_holes(e.fst));
            case Or_intro0:
                return Term.or_intro0(number_new_holes(e.fst));
            case And_elim1:
                return Term.and_elim1(number_new_holes(e.fst));
            case And_elim0:
                return Term.and_elim0(number_new_holes(e.fst));
            case And_intro:
                return Term.and_intro(number_new_holes(e.fst), number_new_holes(e.snd));
            case Lam:
                return Term.lam(e.fst.symbol, number_new_holes(e.snd));
            case App:
                return Term.app(number_new_holes(e.fst), number_new_holes(e.snd));
            case Var:
                return e;
            case Ann:
                return Term.ann(number_new_holes(e.fst), e.ann_type);
            case Hole:
                if (e.hole_num != null) return Term.hole(e.hole_num);
                else return Term.hole(use_hole_ctr());
            default:
                throw new RuntimeException("unreachable in number_new_holes");
        }
    }

    Term replace_goal_with(int n, Term repl, Term e) {
        switch (e.t) {
            case Bot_elim:
                return Term.bot_elim(replace_goal_with(n, repl, e.fst));
            case And_elim1:
                return Term.and_elim1(replace_goal_with(n, repl, e.fst));
            case And_elim0:
                return Term.and_elim0(replace_goal_with(n, repl, e.fst));
            case And_intro:
                return Term.and_intro(replace_goal_with(n, repl, e.fst),
                                      replace_goal_with(n, repl, e.snd));
            case Or_elim:
                return Term.or_elim(replace_goal_with(n, repl, e.fst),
                                    replace_goal_with(n, repl, e.snd),
                                    replace_goal_with(n, repl, e.thr));
            case Or_intro1:
                return Term.or_intro1(replace_goal_with(n, repl, e.fst));
            case Or_intro0:
                return Term.or_intro0(replace_goal_with(n, repl, e.fst));
            case Lam:
                return Term.lam(e.fst.symbol, replace_goal_with(n, repl, e.snd));
            case App:
                return Term.app(replace_goal_with(n, repl, e.fst),
                                replace_goal_with(n, repl, e.snd));
            case Var:
                return e;
            case Ann:
                return Term.ann(replace_goal_with(n, repl, e.fst), e.ann_type);
            case Hole:
                if (e.hole_num == n) return repl;
                else return Term.hole(e.hole_num);
            default:
                throw new RuntimeException("unreachable");
        }
    }

    void refine(int n, Term e) {
        Pair<Type, ContextNode> pair = goal_table.get(n);
        Type t = pair.x;
        ContextNode ctx = pair.y;
        type_check(ctx, e, t); // first time, just check
        Term en = number_new_holes(e);
        refining = true;
        type_check(ctx, en, t); // second time, add goals to table
        refining = false;
        goal_table.remove(n);
        current_expr = replace_goal_with(n, en, current_expr);
        System.out.println("\nTask with " + goal_table.size() + " goals is now\n" + current_expr);
        print_goal();
    }

    static Term var(String s) {
        return Term.var(s);
    }

    static Term lam(String s, Term body) {
        return Term.lam(s, body);
    }

    static Term app(Term rator, Term rand) {
        return Term.app(rator, rand);
    }

    static Term ann(Term expr, Type ann_type) {
        return Term.ann(expr, ann_type);
    }

    static Term hole(int hole_num) {
        return Term.hole(hole_num);
    }

    static Term hole() {
        return Term.hole();
    }

    static Term and_intro(Term t1, Term t2) {
        return Term.and_intro(t1, t2);
    }

    static Term and_elim0(Term t) {
        return Term.and_elim0(t);
    }

    static Term and_elim1(Term t) {
        return Term.and_elim1(t);
    }

    static Term or_intro0(Term t) {
        return Term.or_intro0(t);
    }

    static Term or_intro1(Term t) {
        return Term.or_intro1(t);
    }

    static Term or_elim(Term t1, Term t2, Term t3) {
        return Term.or_elim(t1, t2, t3);
    }

    static Term bot_elim(Term t) {
        return Term.bot_elim(t);
    }

    void test() {
        if (true) {

            // tests not from exercises
            {
                set_task("((A | B) -> (B | A))");
                refine(0, Term.lam("d", Term.hole()));
                Term soy2 = Term.lam("a", Term.or_intro1(Term.var("a")));
                Term soy3 = Term.lam("b", Term.or_intro0(Term.var("b")));
                refine(1, Term.or_elim(Term.var("d"), soy2, soy3));
            }
            {
                set_task("((A | A) -> A)");
                refine(0, Term.lam("d", Term.hole()));
                Term l = Term.lam("a", Term.var("a"));
                refine(1, Term.or_elim(Term.var("d"), l, l));
            }
            {
                set_task("((Bot | A) -> A)");
                refine(0, Term.lam("a", Term.hole()));
                Term id = Term.lam("x", Term.var("x"));
                Term bot_elim = Term.lam("x", Term.bot_elim(Term.var("x")));
                refine(1, Term.or_elim(Term.var("a"), bot_elim, id));
            }
            {
                set_task("((A & -A) -> B)");
                refine(0, Term.lam("a", Term.hole()));
                Term a = Term.and_elim0(Term.var("a"));
                Term a2bot = Term.and_elim1(Term.var("a"));
                Term bot = Term.app(a2bot, a);
                refine(1, Term.bot_elim(bot));
            }
            {
                set_task("(A -> --A)");
                refine(0, Term.lam("a", Term.hole()));
                refine(1, Term.lam("b", Term.hole()));
                refine(2, Term.app(Term.var("b"), Term.var("a")));
            }

            // exercise 0
            {
                set_task("((A -> (B -> C)) -> ((A -> B) -> (A -> C)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, lam("x", hole()));
                refine(3, app(app(var("z"), var("x")), app(var("y"), var("x"))));
            }
            {
                set_task("(((A -> B) -> (A -> C)) -> (A -> (B -> C)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, lam("x", hole()));
                refine(3, app(app(var("z"), lam("y", var("x"))), var("y")));
            }
            {
                set_task("((B -> C) -> ((A -> B) -> (A -> C)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, lam("x", hole()));
                refine(3, app(var("z"), app(var("y"), var("x"))));
            }

            // exercise 2
            {
                set_task("(((A & B) -> C) -> (A -> (B -> C)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, lam("x", hole()));
                refine(3, app(var("z"), and_intro(var("y"), var("x"))));
            }
            {
                set_task("((A -> (B -> C)) -> ((A & B) -> C))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, app(app(var("z"), and_elim0(var("y"))), and_elim1(var("y"))));
            }
            {
                set_task("((A -> B) -> ((A & C) -> (B & C)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, and_intro(app(var("z"), and_elim0(var("y"))), and_elim1(var("y"))));
            }
            {
                set_task("(((A -> B) & (C -> D)) -> ((A & C) -> (B & D)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, and_intro(app(and_elim0(var("z")), and_elim0(var("y"))),
                                    app(and_elim1(var("z")), and_elim1(var("y")))));
            }

            // exercise 4
            {
                set_task("((A -> B) -> ((A | C) -> (B | C)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, or_elim(var("y"), lam("x", or_intro0(app(var("z"), var("x")))),
                                  lam("x", or_intro1(var("x")))));
            }
            {
                set_task("(((A | B) | C) -> (A | (B | C)))");
                refine(0, lam("z", hole()));
                refine(1, or_elim(var("z"),
                                  lam("ab", or_elim(var("ab"),
                                                    lam("a", or_intro0(var("a"))),
                                                    lam("b", or_intro1(or_intro0(var("b")))))),
                                  lam("c", or_intro1(or_intro1(var("c"))))));
            }
            {
                set_task("((A & (B | C)) -> ((A & B) | (A & C)))");
                refine(0, lam("z", hole()));
                Term a = and_elim0(var("z"));
                Term borc = and_elim1(var("z"));
                refine(1, or_elim(borc,
                                  lam("b", or_intro0(and_intro(a, var("b")))),
                                  lam("c", or_intro1(and_intro(a, var("c"))))));
            }
            {
                set_task("((A -> (B | C)) -> ((B -> D) -> ((C -> D) -> (A -> D))))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, lam("x", hole()));
                refine(3, lam("w", hole()));
                Term borc = app(var("z"), var("w"));
                refine(4, or_elim(borc, var("y"), var("x")));
            }

            // exercise 6
            {
                set_task("((A -> B) -> (-B -> -A))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, lam("x", hole()));
                refine(3, app(var("y"), app(var("z"), var("x"))));
            }
            {
                set_task("(-(A | B) -> (A -> B))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, bot_elim(app(var("z"), or_intro0(var("y")))));
            }
            {
                set_task("((A -> (B | C)) -> (-B -> (-C -> -A)))");
                refine(0, lam("z", hole()));
                refine(1, lam("y", hole()));
                refine(2, lam("x", hole()));
                refine(3, lam("w", hole()));
                refine(4, or_elim(app(var("z"), var("w")), var("y"), var("x")));
            }
            {
                set_task("(-(A | B) -> (-A & -B))");
                refine(0, lam("z", hole()));
                refine(1, and_intro(hole(), hole()));
                refine(2, lam("y", hole()));
                refine(3, lam("x", hole()));
                refine(4, app(var("z"), or_intro0(var("y"))));
                refine(5, app(var("z"), or_intro1(var("x"))));
            }

            // kripke
            {
                Parser parser = new Parser();
                {
                    Type t = parser.parse_type("(--A -> A)");
                    Type t2 = Type.arrow(Type.var("A"), Type.bot());
                    Type t1 = Type.arrow(t2, Type.bot());
                    KripkeNode k1 = new KripkeNode();
                    KripkeNode k2 = new KripkeNode();
                    k1.variables.add(t1);
                    k2.variables.add(t1);
                    k2.variables.add(t2);
                    k1.descendants.add(k2);
                    System.out.println(k1.is_valid() + " " + k1.is_forced(t));
                }
                {
                    Type t = parser.parse_type("(-(A & B) -> (-A | -B))");
                    Type t1 = Type.arrow(Type.and(Type.var("A"), Type.var("B")), Type.bot());
                    KripkeNode r = new KripkeNode();
                    r.variables.add(t1);
                    System.out.println(r.is_valid() + " " + r.is_forced(t));
                }
                {
                    Type t = parser.parse_type("(((A -> B) -> A) -> A)");
                    KripkeNode r = new KripkeNode();
                    r.variables.add(Type.arrow(Type.arrow(Type.var("A"),
                                                          Type.var("B")),
                                               Type.var("A")));
                    System.out.println(r.is_valid() + " " + r.is_forced(t));
                }
                {
                    Type t = parser.parse_type("((A -> B) | (B -> A))");
                    KripkeNode r = new KripkeNode();
                    KripkeNode c1 = new KripkeNode();
                    KripkeNode c2 = new KripkeNode();
                    c1.variables.add(Type.var("A"));
                    c2.variables.add(Type.var("B"));
                    r.descendants.add(c1);
                    r.descendants.add(c2);
                    System.out.println(r.is_valid() + " " + r.is_forced(t));
                }
            }

            // exercise 9
            {
                set_task("--(A | -A)");
                refine(0, lam("z", hole()));
                refine(1, app(var("z"), hole()));
                refine(2, or_intro1(hole()));
                refine(3, lam("y", hole()));
                refine(4, app(var("z"), or_intro0(var("y"))));
            }
            {
                set_task("--(--A -> A)");
                refine(0, lam("z", hole()));
                refine(1, app(var("z"), hole()));
                refine(2, lam("y", hole()));
                refine(3, bot_elim(hole()));
                refine(4, app(var("y"), hole()));
                refine(5, lam("x", hole()));
                refine(6, app(var("z"), hole()));
                refine(7, lam("w", hole()));
                refine(8, var("x"));
            }
        }
    }

    public static void main(String[] args) {
        proust_2 proust = new proust_2();
        proust.test();
    }
}


